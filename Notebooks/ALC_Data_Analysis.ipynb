{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Learner Corpus Considerations: Classifier Training and Data Analysis\n",
    "Anthony Verardi | a.verardi@pitt.edu | 3/17/2020 | University of Pittsburgh\n",
    "\n",
    "In this Notebook (which is a continuation of [ALC Data Organization](https://github.com/Data-Science-for-Linguists-2020/Arabic-Learner-Corpus-Considerations/blob/master/Notebooks/ALC_Data_Organization.ipynb)), I'll begin the process of analyzing the data obtained from the [Arabic Learner Corpus](https://www.arabiclearnercorpus.com/).\n",
    "\n",
    "Corpus credit to: Alfaifi, A., Atwell, E. and Hedaya, I. (2014). Arabic Learner Corpus (ALC) v2: A New Written and Spoken Corpus of Arabic Learners. In the proceedings of the Learner Corpus Studies in Asia and the World (LCSAW) 2014, 31 May - 01 Jun 2014. Kobe, Japan. http://www.arabiclearnercorpus.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages to begin reading in our data. The files come in XML format,\n",
    "# so we'll need to import a library, BeautifulSoup, that can read them in and get the data\n",
    "# ready for input into a DataFrame. Glob is for easily working with batches of files at once.\n",
    "\n",
    "import nltk, glob, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Allowing for multiple lines of output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"ALC_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>NumLangs</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>YearsStudy</th>\n",
       "      <th>GenLvl</th>\n",
       "      <th>LvlStdy</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Mode</th>\n",
       "      <th>TextToks</th>\n",
       "      <th>TitleToks</th>\n",
       "      <th>TextLen</th>\n",
       "      <th>TitleLen</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DocID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>S001_T1_M_Pre_NNAS_W_C</td>\n",
       "      <td>Moore</td>\n",
       "      <td>4</td>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>Pre-university</td>\n",
       "      <td>Diploma course</td>\n",
       "      <td>الرحلة إلى القرية لزيارة ذوي القربى</td>\n",
       "      <td>اعتدت الذهاب إلى قريتي في الإجازات الصيفيّة ال...</td>\n",
       "      <td>Narrative</td>\n",
       "      <td>Written</td>\n",
       "      <td>[اعتدت, الذهاب, إلى, قريتي, في, الإجازات, الصي...</td>\n",
       "      <td>[الرحلة, إلى, القرية, لزيارة, ذوي, القربى]</td>\n",
       "      <td>169</td>\n",
       "      <td>6</td>\n",
       "      <td>0.798817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>S001_T2_M_Pre_NNAS_W_C</td>\n",
       "      <td>Moore</td>\n",
       "      <td>4</td>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>Pre-university</td>\n",
       "      <td>Diploma course</td>\n",
       "      <td>الجمع بين العلم الشرعي والعلوم الدنيوية لحمزة ...</td>\n",
       "      <td>أحبّ أن ألتحق بكلِّية الشريعة بعد الانتها من ا...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Written</td>\n",
       "      <td>[أحبّ, أن, ألتحق, بكلِّية, الشريعة, بعد, الانت...</td>\n",
       "      <td>[الجمع, بين, العلم, الشرعي, والعلوم, الدنيوية,...</td>\n",
       "      <td>161</td>\n",
       "      <td>9</td>\n",
       "      <td>0.844720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>S002_T1_M_Pre_NNAS_W_C</td>\n",
       "      <td>Russian</td>\n",
       "      <td>5</td>\n",
       "      <td>Russian</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>5</td>\n",
       "      <td>Pre-university</td>\n",
       "      <td>Diploma course</td>\n",
       "      <td>رحلة الحج المباركة</td>\n",
       "      <td>كتب الله لي أن أحج إلى بيته الحرام السنة الماض...</td>\n",
       "      <td>Narrative</td>\n",
       "      <td>Written</td>\n",
       "      <td>[كتب, الله, لي, أن, أحج, إلى, بيته, الحرام, ال...</td>\n",
       "      <td>[رحلة, الحج, المباركة]</td>\n",
       "      <td>317</td>\n",
       "      <td>3</td>\n",
       "      <td>0.637224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>S002_T2_M_Pre_NNAS_W_C</td>\n",
       "      <td>Russian</td>\n",
       "      <td>5</td>\n",
       "      <td>Russian</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>5</td>\n",
       "      <td>Pre-university</td>\n",
       "      <td>Diploma course</td>\n",
       "      <td>أكثر من التخصص</td>\n",
       "      <td>الحمد لله الذي وفقني لدراسة شرعية في جامعة الإ...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>Written</td>\n",
       "      <td>[الحمد, لله, الذي, وفقني, لدراسة, شرعية, في, ج...</td>\n",
       "      <td>[أكثر, من, التخصص]</td>\n",
       "      <td>173</td>\n",
       "      <td>3</td>\n",
       "      <td>0.757225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>S003_T1_M_Pre_NNAS_W_C</td>\n",
       "      <td>Tatar</td>\n",
       "      <td>4</td>\n",
       "      <td>Russian</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>6</td>\n",
       "      <td>Pre-university</td>\n",
       "      <td>Diploma course</td>\n",
       "      <td>رحلتي إلى الجبال</td>\n",
       "      <td>في أحد الأيام الصيف أخبرنا أبي بسفرٍ إلى الغاب...</td>\n",
       "      <td>Narrative</td>\n",
       "      <td>Written</td>\n",
       "      <td>[في, أحد, الأيام, الصيف, أخبرنا, أبي, بسفرٍ, إ...</td>\n",
       "      <td>[رحلتي, إلى, الجبال]</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>0.766917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             L1  NumLangs   Nationality Age Gender  \\\n",
       "DocID                                                                \n",
       "S001_T1_M_Pre_NNAS_W_C    Moore         4  Burkina Faso  20   Male   \n",
       "S001_T2_M_Pre_NNAS_W_C    Moore         4  Burkina Faso  20   Male   \n",
       "S002_T1_M_Pre_NNAS_W_C  Russian         5       Russian  25   Male   \n",
       "S002_T2_M_Pre_NNAS_W_C  Russian         5       Russian  25   Male   \n",
       "S003_T1_M_Pre_NNAS_W_C    Tatar         4       Russian  24   Male   \n",
       "\n",
       "                        YearsStudy          GenLvl         LvlStdy  \\\n",
       "DocID                                                                \n",
       "S001_T1_M_Pre_NNAS_W_C          14  Pre-university  Diploma course   \n",
       "S001_T2_M_Pre_NNAS_W_C          14  Pre-university  Diploma course   \n",
       "S002_T1_M_Pre_NNAS_W_C           5  Pre-university  Diploma course   \n",
       "S002_T2_M_Pre_NNAS_W_C           5  Pre-university  Diploma course   \n",
       "S003_T1_M_Pre_NNAS_W_C           6  Pre-university  Diploma course   \n",
       "\n",
       "                                                                    Title  \\\n",
       "DocID                                                                       \n",
       "S001_T1_M_Pre_NNAS_W_C                الرحلة إلى القرية لزيارة ذوي القربى   \n",
       "S001_T2_M_Pre_NNAS_W_C  الجمع بين العلم الشرعي والعلوم الدنيوية لحمزة ...   \n",
       "S002_T1_M_Pre_NNAS_W_C                                 رحلة الحج المباركة   \n",
       "S002_T2_M_Pre_NNAS_W_C                                     أكثر من التخصص   \n",
       "S003_T1_M_Pre_NNAS_W_C                                   رحلتي إلى الجبال   \n",
       "\n",
       "                                                                     Text  \\\n",
       "DocID                                                                       \n",
       "S001_T1_M_Pre_NNAS_W_C  اعتدت الذهاب إلى قريتي في الإجازات الصيفيّة ال...   \n",
       "S001_T2_M_Pre_NNAS_W_C  أحبّ أن ألتحق بكلِّية الشريعة بعد الانتها من ا...   \n",
       "S002_T1_M_Pre_NNAS_W_C  كتب الله لي أن أحج إلى بيته الحرام السنة الماض...   \n",
       "S002_T2_M_Pre_NNAS_W_C  الحمد لله الذي وفقني لدراسة شرعية في جامعة الإ...   \n",
       "S003_T1_M_Pre_NNAS_W_C  في أحد الأيام الصيف أخبرنا أبي بسفرٍ إلى الغاب...   \n",
       "\n",
       "                             Genre     Mode  \\\n",
       "DocID                                         \n",
       "S001_T1_M_Pre_NNAS_W_C   Narrative  Written   \n",
       "S001_T2_M_Pre_NNAS_W_C  Discussion  Written   \n",
       "S002_T1_M_Pre_NNAS_W_C   Narrative  Written   \n",
       "S002_T2_M_Pre_NNAS_W_C  Discussion  Written   \n",
       "S003_T1_M_Pre_NNAS_W_C   Narrative  Written   \n",
       "\n",
       "                                                                 TextToks  \\\n",
       "DocID                                                                       \n",
       "S001_T1_M_Pre_NNAS_W_C  [اعتدت, الذهاب, إلى, قريتي, في, الإجازات, الصي...   \n",
       "S001_T2_M_Pre_NNAS_W_C  [أحبّ, أن, ألتحق, بكلِّية, الشريعة, بعد, الانت...   \n",
       "S002_T1_M_Pre_NNAS_W_C  [كتب, الله, لي, أن, أحج, إلى, بيته, الحرام, ال...   \n",
       "S002_T2_M_Pre_NNAS_W_C  [الحمد, لله, الذي, وفقني, لدراسة, شرعية, في, ج...   \n",
       "S003_T1_M_Pre_NNAS_W_C  [في, أحد, الأيام, الصيف, أخبرنا, أبي, بسفرٍ, إ...   \n",
       "\n",
       "                                                                TitleToks  \\\n",
       "DocID                                                                       \n",
       "S001_T1_M_Pre_NNAS_W_C         [الرحلة, إلى, القرية, لزيارة, ذوي, القربى]   \n",
       "S001_T2_M_Pre_NNAS_W_C  [الجمع, بين, العلم, الشرعي, والعلوم, الدنيوية,...   \n",
       "S002_T1_M_Pre_NNAS_W_C                             [رحلة, الحج, المباركة]   \n",
       "S002_T2_M_Pre_NNAS_W_C                                 [أكثر, من, التخصص]   \n",
       "S003_T1_M_Pre_NNAS_W_C                               [رحلتي, إلى, الجبال]   \n",
       "\n",
       "                        TextLen  TitleLen       TTR  \n",
       "DocID                                                \n",
       "S001_T1_M_Pre_NNAS_W_C      169         6  0.798817  \n",
       "S001_T2_M_Pre_NNAS_W_C      161         9  0.844720  \n",
       "S002_T1_M_Pre_NNAS_W_C      317         3  0.637224  \n",
       "S002_T2_M_Pre_NNAS_W_C      173         3  0.757225  \n",
       "S003_T1_M_Pre_NNAS_W_C      133         3  0.766917  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as far as I think I'm going to get with everything going on right now. The plan is as follows:\n",
    "\n",
    "* Add a column for language family (I might go back and do this in the Organization notebook instead)\n",
    "* Run some tests to see how the data are distributed within learner groups (a Shapiro test might not be needed/useful since there are over 30 observations, but it might still be good to go through)\n",
    "* Partition data into training, testing, and development sets\n",
    "* Train a classifier and see if it can reliably tell apart the differences in writing between L1-Arabic learners of Modern Standard Arabic (MSA) and non-L1-Arabic learners of MSA\n",
    "* Try to eek out what the differences ARE between L1-Arabic learners and non-L1-Arabic learners, and what features are useful indicators of these differences\n",
    "* I'd like to try another tokenizer that handles Arabic morphosyntax more elegantly (the NLTK version doesn't split words into morphemes, so for+her is rendered as one token instead of \"for\" and \"her\" for example), but I could use a hand finding/implementing one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                              L1  NumLangs   Nationality Age  Gender  \\\n",
       "DocID                                                                 \n",
       "S001_T1_M_Pre_NNAS_W_C    Moore         4  Burkina Faso  20    Male   \n",
       "S001_T2_M_Pre_NNAS_W_C    Moore         4  Burkina Faso  20    Male   \n",
       "S002_T1_M_Pre_NNAS_W_C  Russian         5       Russian  25    Male   \n",
       "S002_T2_M_Pre_NNAS_W_C  Russian         5       Russian  25    Male   \n",
       "S003_T1_M_Pre_NNAS_W_C    Tatar         4       Russian  24    Male   \n",
       "...                         ...       ...           ...  ..     ...   \n",
       "S939_T1_F_Uni_NNAS_S_C  Swahili         3      Comorian  23  Female   \n",
       "S939_T2_F_Uni_NNAS_S_C  Swahili         3      Comorian  23  Female   \n",
       "S940_T1_M_Pre_NNAS_S_C   Yoruba         3      Nigerian  26    Male   \n",
       "S941_T1_M_Pre_NNAS_S_C     Urdu         3      Nepalese  25    Male   \n",
       "S942_T1_M_Uni_NAS_S_C    Arabic         1         Saudi  23    Male   \n",
       "\n",
       "                        YearsStudy          GenLvl         LvlStdy  \\\n",
       "DocID                                                                \n",
       "S001_T1_M_Pre_NNAS_W_C          14  Pre-university  Diploma course   \n",
       "S001_T2_M_Pre_NNAS_W_C          14  Pre-university  Diploma course   \n",
       "S002_T1_M_Pre_NNAS_W_C           5  Pre-university  Diploma course   \n",
       "S002_T2_M_Pre_NNAS_W_C           5  Pre-university  Diploma course   \n",
       "S003_T1_M_Pre_NNAS_W_C           6  Pre-university  Diploma course   \n",
       "...                            ...             ...             ...   \n",
       "S939_T1_F_Uni_NNAS_S_C           3      University              BA   \n",
       "S939_T2_F_Uni_NNAS_S_C           3      University              BA   \n",
       "S940_T1_M_Pre_NNAS_S_C           8  Pre-university  Diploma course   \n",
       "S941_T1_M_Pre_NNAS_S_C           5  Pre-university  Diploma course   \n",
       "S942_T1_M_Uni_NAS_S_C            0      University              BA   \n",
       "\n",
       "                                                                    Title  \\\n",
       "DocID                                                                       \n",
       "S001_T1_M_Pre_NNAS_W_C                الرحلة إلى القرية لزيارة ذوي القربى   \n",
       "S001_T2_M_Pre_NNAS_W_C  الجمع بين العلم الشرعي والعلوم الدنيوية لحمزة ...   \n",
       "S002_T1_M_Pre_NNAS_W_C                                 رحلة الحج المباركة   \n",
       "S002_T2_M_Pre_NNAS_W_C                                     أكثر من التخصص   \n",
       "S003_T1_M_Pre_NNAS_W_C                                   رحلتي إلى الجبال   \n",
       "...                                                                   ...   \n",
       "S939_T1_F_Uni_NNAS_S_C                                                قصة   \n",
       "S939_T2_F_Uni_NNAS_S_C                                             التخصص   \n",
       "S940_T1_M_Pre_NNAS_S_C                                             التخصص   \n",
       "S941_T1_M_Pre_NNAS_S_C                                             التخصص   \n",
       "S942_T1_M_Uni_NAS_S_C                                                 قصة   \n",
       "\n",
       "                                                                     Text  \\\n",
       "DocID                                                                       \n",
       "S001_T1_M_Pre_NNAS_W_C  اعتدت الذهاب إلى قريتي في الإجازات الصيفيّة ال...   \n",
       "S001_T2_M_Pre_NNAS_W_C  أحبّ أن ألتحق بكلِّية الشريعة بعد الانتها من ا...   \n",
       "S002_T1_M_Pre_NNAS_W_C  كتب الله لي أن أحج إلى بيته الحرام السنة الماض...   \n",
       "S002_T2_M_Pre_NNAS_W_C  الحمد لله الذي وفقني لدراسة شرعية في جامعة الإ...   \n",
       "S003_T1_M_Pre_NNAS_W_C  في أحد الأيام الصيف أخبرنا أبي بسفرٍ إلى الغاب...   \n",
       "...                                                                   ...   \n",
       "S939_T1_F_Uni_NNAS_S_C  أ- بسم الله الرحمن الرحيم\\nالاسم #معلومة شخصية...   \n",
       "S939_T2_F_Uni_NNAS_S_C  أ- بسم الله الرحمن الرحيم\\nأ- أ ق أ أنا في الج...   \n",
       "S940_T1_M_Pre_NNAS_S_C  الحمد لله، والصلاة والسلام على أشرف المرسلين، ...   \n",
       "S941_T1_M_Pre_NNAS_S_C  السلام عليكم ورحمة الله وبركاته\\nأنا أخوكم #مع...   \n",
       "S942_T1_M_Uni_NAS_S_C   بسم الله الرحمن الرحيم\\nوالصلاة والسلام على رس...   \n",
       "\n",
       "                             Genre     Mode  \\\n",
       "DocID                                         \n",
       "S001_T1_M_Pre_NNAS_W_C   Narrative  Written   \n",
       "S001_T2_M_Pre_NNAS_W_C  Discussion  Written   \n",
       "S002_T1_M_Pre_NNAS_W_C   Narrative  Written   \n",
       "S002_T2_M_Pre_NNAS_W_C  Discussion  Written   \n",
       "S003_T1_M_Pre_NNAS_W_C   Narrative  Written   \n",
       "...                            ...      ...   \n",
       "S939_T1_F_Uni_NNAS_S_C   Narrative   Spoken   \n",
       "S939_T2_F_Uni_NNAS_S_C  Discussion   Spoken   \n",
       "S940_T1_M_Pre_NNAS_S_C  Discussion   Spoken   \n",
       "S941_T1_M_Pre_NNAS_S_C  Discussion   Spoken   \n",
       "S942_T1_M_Uni_NAS_S_C    Narrative   Spoken   \n",
       "\n",
       "                                                                 TextToks  \\\n",
       "DocID                                                                       \n",
       "S001_T1_M_Pre_NNAS_W_C  [اعتدت, الذهاب, إلى, قريتي, في, الإجازات, الصي...   \n",
       "S001_T2_M_Pre_NNAS_W_C  [أحبّ, أن, ألتحق, بكلِّية, الشريعة, بعد, الانت...   \n",
       "S002_T1_M_Pre_NNAS_W_C  [كتب, الله, لي, أن, أحج, إلى, بيته, الحرام, ال...   \n",
       "S002_T2_M_Pre_NNAS_W_C  [الحمد, لله, الذي, وفقني, لدراسة, شرعية, في, ج...   \n",
       "S003_T1_M_Pre_NNAS_W_C  [في, أحد, الأيام, الصيف, أخبرنا, أبي, بسفرٍ, إ...   \n",
       "...                                                                   ...   \n",
       "S939_T1_F_Uni_NNAS_S_C  [أ-, بسم, الله, الرحمن, الرحيم, الاسم, #, معلو...   \n",
       "S939_T2_F_Uni_NNAS_S_C  [أ-, بسم, الله, الرحمن, الرحيم, أ-, أ, ق, أ, أ...   \n",
       "S940_T1_M_Pre_NNAS_S_C  [الحمد, لله،, والصلاة, والسلام, على, أشرف, الم...   \n",
       "S941_T1_M_Pre_NNAS_S_C  [السلام, عليكم, ورحمة, الله, وبركاته, أنا, أخو...   \n",
       "S942_T1_M_Uni_NAS_S_C   [بسم, الله, الرحمن, الرحيم, والصلاة, والسلام, ...   \n",
       "\n",
       "                                                                TitleToks  \\\n",
       "DocID                                                                       \n",
       "S001_T1_M_Pre_NNAS_W_C         [الرحلة, إلى, القرية, لزيارة, ذوي, القربى]   \n",
       "S001_T2_M_Pre_NNAS_W_C  [الجمع, بين, العلم, الشرعي, والعلوم, الدنيوية,...   \n",
       "S002_T1_M_Pre_NNAS_W_C                             [رحلة, الحج, المباركة]   \n",
       "S002_T2_M_Pre_NNAS_W_C                                 [أكثر, من, التخصص]   \n",
       "S003_T1_M_Pre_NNAS_W_C                               [رحلتي, إلى, الجبال]   \n",
       "...                                                                   ...   \n",
       "S939_T1_F_Uni_NNAS_S_C                                              [قصة]   \n",
       "S939_T2_F_Uni_NNAS_S_C                                           [التخصص]   \n",
       "S940_T1_M_Pre_NNAS_S_C                                           [التخصص]   \n",
       "S941_T1_M_Pre_NNAS_S_C                                           [التخصص]   \n",
       "S942_T1_M_Uni_NAS_S_C                                               [قصة]   \n",
       "\n",
       "                        TextLen  TitleLen       TTR  \n",
       "DocID                                                \n",
       "S001_T1_M_Pre_NNAS_W_C      169         6  0.798817  \n",
       "S001_T2_M_Pre_NNAS_W_C      161         9  0.844720  \n",
       "S002_T1_M_Pre_NNAS_W_C      317         3  0.637224  \n",
       "S002_T2_M_Pre_NNAS_W_C      173         3  0.757225  \n",
       "S003_T1_M_Pre_NNAS_W_C      133         3  0.766917  \n",
       "...                         ...       ...       ...  \n",
       "S939_T1_F_Uni_NNAS_S_C      212         1  0.533019  \n",
       "S939_T2_F_Uni_NNAS_S_C       48         1  0.625000  \n",
       "S940_T1_M_Pre_NNAS_S_C      296         1  0.587838  \n",
       "S941_T1_M_Pre_NNAS_S_C      244         1  0.586066  \n",
       "S942_T1_M_Uni_NAS_S_C      1086         1  0.583794  \n",
       "\n",
       "[1585 rows x 17 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfIdf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=2,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                      n_iter_no_change=10,\n",
       "                                                      nesterovs_momentum=True,\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=1,\n",
       "                                                      shuffle=True,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=False,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'mlp__solver': ('adam', 'lbfgs'),\n",
       "                         'tfIdf__max_features': [2000, 5000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1)\n",
    "tfIdf = TfidfVectorizer(min_df=2, max_df=.5)\n",
    "\n",
    "pipe = Pipeline(steps=[('tfIdf', tfIdf),('mlp',mlp)])\n",
    "\n",
    "# Trying two different solvers, one of which (lbfgs) is supposed to be quicker and better for smaller\n",
    "# data sets\n",
    "clf = GridSearchCV(pipe, param_grid = {\"tfIdf__max_features\":[2000, 5000],\n",
    "                                      \"mlp__solver\":('adam','lbfgs')}, cv=5, return_train_score=True)\n",
    "\n",
    "clf.fit(df.Text, df.L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=3000,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=100000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_model = make_pipeline(TfidfVectorizer(max_features = 3000), SVC(kernel='rbf', C=1E5))\n",
    "SVC_model.fit(df.Text, df.L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "labels = SVC_model.predict(df.Text)\n",
    "\n",
    "# Matrix\n",
    "matrix = confusion_matrix(df.L1, labels)\n",
    "\n",
    "# Accuracy assessment\n",
    "accuracy = accuracy_score(df.L1, Prompt_SVC_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfIdf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=2,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='auto_deprecated',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'tfIdf__max_features': [2000, 5000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = sklearn.svm.SVC(kernel='rbf', C=1E5)\n",
    "tfIdf = TfidfVectorizer(min_df=2, max_df=.5)\n",
    "\n",
    "pipe = Pipeline(steps=[('tfIdf', tfIdf),('svc',svc)])\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = {\"tfIdf__max_features\":[2000, 5000]}, cv=3, return_train_score=True)\n",
    "\n",
    "clf.fit(df.Text, df.L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfIdf__max_features': 5000}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tfIdf__max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.987985</td>\n",
       "      <td>0.313749</td>\n",
       "      <td>0.632830</td>\n",
       "      <td>0.056506</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'tfIdf__max_features': 2000}</td>\n",
       "      <td>0.528777</td>\n",
       "      <td>0.569260</td>\n",
       "      <td>0.579681</td>\n",
       "      <td>0.55836</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.046199</td>\n",
       "      <td>0.709656</td>\n",
       "      <td>0.850659</td>\n",
       "      <td>0.062294</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'tfIdf__max_features': 5000}</td>\n",
       "      <td>0.534173</td>\n",
       "      <td>0.578748</td>\n",
       "      <td>0.585657</td>\n",
       "      <td>0.56530</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.987985      0.313749         0.632830        0.056506   \n",
       "1       6.046199      0.709656         0.850659        0.062294   \n",
       "\n",
       "  param_tfIdf__max_features                         params  split0_test_score  \\\n",
       "0                      2000  {'tfIdf__max_features': 2000}           0.528777   \n",
       "1                      5000  {'tfIdf__max_features': 5000}           0.534173   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.569260           0.579681          0.55836        0.022147   \n",
       "1           0.578748           0.585657          0.56530        0.023049   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                2                 1.0                 1.0   \n",
       "1                1                 1.0                 1.0   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0                 1.0               1.0              0.0  \n",
       "1                 1.0               1.0              0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
